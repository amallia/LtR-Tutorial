{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Efficiency/Effectiveness Trade-offs in Learning to Rank\n",
    "### Tutorial @ ECML-PKDD 2018, HandsOn Session N. 1\n",
    "\n",
    "##### Claudio Lucchese (UniVe), Franco Maria Nardini (ISTI-CNR)\n",
    "##### High Performance Computing Lab. http://hpc.isti.cnr.it/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hpc.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from rankeval.dataset import Dataset\n",
    "from rankeval.model import RTEnsemble\n",
    "from rankeval.analysis.effectiveness import tree_wise_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "Given a trained LambdaMART model (stored in QuickRank format):\n",
    "\n",
    "0. setup of an experimental environment for testing different scoring methods: Conditional Operators (CondOp), VPred, QuickScorer (QS), Vectorized QuickScorer (v-QS).\n",
    "0. Execution of the different methods and comparison.\n",
    "0. Low-level analysis with ``perf`` for two of them: VPred vs QuickScorer\n",
    "0. Comparison with previously published results [QS-TOIS16, QS-TPDS18].\n",
    "\n",
    "** Bonus Track **\n",
    "\n",
    "0. Multi-threaded implementation of Vectorized QuickScorer.\n",
    "0. GPU implementation of QuickScorer.\n",
    "0. Multi-threaded scoring with RankEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0\n",
    "\n",
    "Clone and compile QuickRank. Detailed instructions on how to do it can be found at: http://quickrank.isti.cnr.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.1\n",
    "\n",
    "Clone and install RankEval. Detailed instructions on how to do it can be found at: http://rankeval.isti.cnr.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.2\n",
    "\n",
    "Download the Istella-S LETOR dataset (http://blog.istella.it/istella-learning-to-rank-dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Options\n",
    "\n",
    "# paths to executable files\n",
    "QUICKRANK      = \"./quickrank/bin/quicklearn\"\n",
    "SCORER         = \"./quickrank/bin/quickscore\"\n",
    "\n",
    "QUICKSCORER    = \"./QuickScorer/bin/quickscorer\"\n",
    "QUICKSCORER_NS = \"./QuickScorer-noscoring/bin/quickscorer\"\n",
    "VPRED          = \"./asadi_tkde13/out/VPred\"\n",
    "VPRED_NS       = \"./asadi_tkde13-noscoring/out/VPred\"\n",
    "\n",
    "PERF           = \"perf\"\n",
    "QUICKSCORER_GPU= \"./QuickScorer-GPU/GPUQS/bin/quickscorer\"\n",
    "\n",
    "# paths to Istella-S dataset\n",
    "train_dataset_file       = \"/data/letor-datasets/tiscali/sample/ramfs/train.txt\"\n",
    "valid_dataset_file       = \"/data/letor-datasets/tiscali/sample/ramfs/vali.txt\"\n",
    "test_dataset_file        = \"/data/letor-datasets/tiscali/sample/ramfs/test.txt\"\n",
    "\n",
    "dataset_size = 681250\n",
    "\n",
    "# The first row of the test file used by VPred should be: \"<# rows of the file> <# features>\\n\".\n",
    "vpred_test_dataset_file  = \"/data/letor-datasets/tiscali/sample/ramfs/test.vpred\"\n",
    "\n",
    "# paths to model file\n",
    "models_folder            = \"models\"\n",
    "baseline_model_file      = os.path.join(models_folder, \"istella-small.lamdamart.xml\")\n",
    "\n",
    "# setting floating point precision of Pandas\n",
    "pd.set_option('precision', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Load an existing LambdaMART model with RankEval or train it with QuickRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a QuickRank model\n",
    "# if no model is available, use the box below to train one!\n",
    "\n",
    "baseline_model = RTEnsemble(baseline_model_file, name=\"Baseline\", format=\"QuickRank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "      _____  _____\n",
      "     /    / /____/\n",
      "    /____\\ /    \\        QuickRank has been developed by hpc.isti.cnr.it\n",
      "    ::Quick:Rank::                             mail: quickrank@isti.cnr.it\n",
      "\u001b[0m\n",
      "\n",
      "# Ranker: LAMBDAMART\n",
      "# max no. of trees = 50\n",
      "# no. of tree leaves = 64\n",
      "# shrinkage = 0.050000\n",
      "# min leaf support = 1\n",
      "# no. of thresholds = unlimited\n",
      "\n",
      "# Reading training dataset: /data/letor-datasets/tiscali/sample/ramfs/train.txt\n",
      "#\t Reading time: 95.56 s. @ 31.52 MB/s  (post-proc.: 1.21 s.)\n",
      "#\t Dataset size: 2043304 x 220 (instances x features)\n",
      "#\t Num queries: 19245 | Avg. len: 106.173\n",
      "\n",
      "# Reading validation dataset: /data/letor-datasets/tiscali/sample/ramfs/vali.txt\n",
      "#\t Reading time: 32.34 s. @ 31.23 MB/s  (post-proc.: 0.27 s.)\n",
      "#\t Dataset size: 684076 x 220 (instances x features)\n",
      "#\t Num queries: 7211 | Avg. len: 94.866\n",
      "\n",
      "#\n",
      "# Ranker: LAMBDAMART\n",
      "# max no. of trees = 50\n",
      "# no. of tree leaves = 64\n",
      "# shrinkage = 0.050\n",
      "# min leaf support = 1\n",
      "# no. of thresholds = unlimited\n",
      "#\n",
      "# training scorer: NDCG@10\n",
      "# Initialization: 2.73 s.\n",
      "# Training:\n",
      "# -------------------------\n",
      "# iter. training validation\n",
      "# -------------------------\n",
      "      1   0.6215   0.5944 *\n",
      "      2   0.6317   0.6027 *\n",
      "      3   0.6403   0.6140 *\n",
      "      4   0.6400   0.6131\n",
      "      5   0.6397   0.6110\n",
      "      6   0.6399   0.6110\n",
      "      7   0.6405   0.6114\n",
      "      8   0.6414   0.6120\n",
      "      9   0.6420   0.6132\n",
      "     10   0.6422   0.6130\n",
      "     11   0.6423   0.6135\n",
      "     12   0.6427   0.6141 *\n",
      "     13   0.6435   0.6153 *\n",
      "     14   0.6440   0.6157 *\n",
      "     15   0.6467   0.6175 *\n",
      "     16   0.6479   0.6196 *\n",
      "     17   0.6490   0.6212 *\n",
      "     18   0.6508   0.6232 *\n",
      "     19   0.6539   0.6265 *\n",
      "     20   0.6564   0.6297 *\n",
      "     21   0.6587   0.6323 *\n",
      "     22   0.6601   0.6346 *\n",
      "     23   0.6618   0.6368 *\n",
      "     24   0.6633   0.6381 *\n",
      "     25   0.6661   0.6410 *\n",
      "     26   0.6680   0.6437 *\n",
      "     27   0.6696   0.6452 *\n",
      "     28   0.6706   0.6461 *\n",
      "     29   0.6719   0.6479 *\n",
      "     30   0.6735   0.6498 *\n",
      "     31   0.6750   0.6513 *\n",
      "     32   0.6762   0.6529 *\n",
      "     33   0.6775   0.6544 *\n",
      "     34   0.6788   0.6559 *\n",
      "     35   0.6799   0.6573 *\n",
      "     36   0.6810   0.6587 *\n",
      "     37   0.6819   0.6597 *\n",
      "     38   0.6830   0.6609 *\n",
      "     39   0.6839   0.6618 *\n",
      "     40   0.6847   0.6628 *\n",
      "     41   0.6859   0.6642 *\n",
      "     42   0.6869   0.6652 *\n",
      "     43   0.6883   0.6660 *\n",
      "     44   0.6893   0.6670 *\n",
      "     45   0.6906   0.6676 *\n",
      "     46   0.6915   0.6686 *\n",
      "     47   0.6931   0.6694 *\n",
      "     48   0.6940   0.6703 *\n",
      "     49   0.6950   0.6721 *\n",
      "     50   0.6960   0.6727 *\n",
      "\n",
      "NDCG@10 on training data = 0.6960\n",
      "NDCG@10 on validation data = 0.6727\n",
      "\n",
      "#\t Training Time: 281.42 s.\n",
      "\n",
      "# Writing model to file: /home/letortutorial/quickrank.1000T.64L.xml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The code below trains a LambdaMART of 50 trees.\n",
    "\n",
    "!{QUICKRANK} \\\n",
    "  --algo LAMBDAMART \\\n",
    "  --num-trees 50 \\\n",
    "  --shrinkage 0.05 \\\n",
    "  --num-thresholds 0 \\\n",
    "  --num-leaves 64 \\\n",
    "  --min-leaf-support 1 \\\n",
    "  --end-after-rounds 0 \\\n",
    "  --partial 1000 \\\n",
    "  --train {train_dataset_file} \\\n",
    "  --valid {valid_dataset_file} \\\n",
    "  --train-metric NDCG \\\n",
    "  --train-cutoff 10 \\\n",
    "  --model-out ~/quickrank.1000T.64L.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "We now translate the LambdaMART model in C++ code employing Conditional Operators to build the final document ranker [QS-TOIS16].\n",
    "\n",
    "QuickRank provides a plugin to convert models stored in its native XML format to C++ source code. The result is that each tree is translated as a nested block of Conditional Operators (https://www.tutorialspoint.com/cplusplus/cpp_conditional_operator.htm). The obtained C++ code can be compiled to produce a working ranked of the given model.\n",
    "\n",
    "Here a toy example of a tree:\n",
    "~~~~\n",
    "<feature>194</feature>\n",
    "<threshold>140</threshold>\n",
    " <split pos=\"left\">\n",
    "   <feature>31</feature>\n",
    "   <threshold>0.0120639997</threshold>\n",
    "     <split pos=\"left\">\n",
    "       <output>-0.78920207999267233</output>\n",
    "     </split>\n",
    "     <split pos=\"right\">\n",
    "       <output>1.1050481952095461</output>\n",
    "     </split>\n",
    " </split>\n",
    "~~~~\n",
    "\n",
    "The conditional operator (BOOLEAN CONDITION ? THEN : ELSE) translation produces:\n",
    "\n",
    "~~~~\n",
    "v[194] <= 140.0f ? ( v[31] <= 0.0120639997f ? -0.78920207999267233 : 1.1050481952095461 )\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use CondOp-based C code as a baseline for the scoring time evaluation\n",
    "\n",
    "def run_condop(model_file, dataset_file, rounds=1):\n",
    "    # create the C code\n",
    "    print (\" 1. Creating the C code for \" + model_file)\n",
    "    condop_source = model_file + \".c\"\n",
    "    condop_compiled = model_file + \".bin\"\n",
    "    \n",
    "    _ = !{QUICKRANK} \\\n",
    "      --generator condop \\\n",
    "      --model-file {model_file} \\\n",
    "      --code-file {condop_source}\n",
    "    \n",
    "    # Compile an executable ranker. The resulting ranker is SCORER=./quickrank/bin/quickscore\n",
    "    print (\" 2. Compiling the model\")\n",
    "\n",
    "    # actually compule only if the model is newer\n",
    "    if ( not os.path.exists(condop_compiled) or \n",
    "          os.path.getmtime(condop_compiled) < os.path.getmtime(baseline_model_file) ):\n",
    "        \n",
    "        # replace empty scorer\n",
    "        !cp {condop_source} ./quickrank/src/scoring/ranker.cc\n",
    "        # compile\n",
    "        _ = !make -j -C ./quickrank/build_ quickscore \n",
    "        # copy compiled scorer\n",
    "        !cp {SCORER} {condop_compiled}\n",
    "\n",
    "    # Now running the Conditional Operators scorer by executing the previously compiled C code.\n",
    "    # QuickScore options:\n",
    "    #  -h,--help                             print help message\n",
    "    #  -d,--dataset <arg>                    Input dataset in SVML format\n",
    "    #  -r,--rounds <arg> (10)                Number of test repetitions\n",
    "    #  -s,--scores <arg>                     File where scores are saved (Optional).\n",
    "    print (\" 3. Running the compiled model\")\n",
    "    cond_op_scorer_out = !{condop_compiled} \\\n",
    "      -d {dataset_file} \\\n",
    "      -r {rounds}\n",
    "    \n",
    "    print (cond_op_scorer_out.n)\n",
    "    \n",
    "    # takes the scoring time in milli-seconds\n",
    "    cond_op_scoring_time = float(cond_op_scorer_out.l[-1].split()[-2])* 10**6\n",
    "    \n",
    "    return cond_op_scoring_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Creating the C code for models/istella-small.lamdamart.xml\n",
      " 2. Compiling the model\n",
      " 3. Running the compiled model\n",
      "\n",
      "      _____  _____\n",
      "     /    / /____/\n",
      "    /____\\ /    \\          QuickRank has been developed by hpc.isti.cnr.it\n",
      "    ::Quick:Rank::                                   quickrank@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "       Total scoring time: 74.6 s.\n",
      "Avg. Dataset scoring time: 74.6 s.\n",
      "Avg.    Doc. scoring time: 0.00011 s.\n"
     ]
    }
   ],
   "source": [
    "condop_efficiency = run_condop(baseline_model_file, test_dataset_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th># Trees</th>\n",
       "      <th>Scoring Time µs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CondOp</td>\n",
       "      <td>1492</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model # Trees  Scoring Time µs.\n",
       "0  CondOp    1492             110.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "results = pd.DataFrame(columns=['Model', '# Trees', 'Scoring Time µs.'])\n",
    "\n",
    "results.loc[len(results)] = ['CondOp', baseline_model.n_trees, condop_efficiency]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Now scoring with VPred [VPRED].\n",
    "\n",
    "First of all, we need to convert the QuickRank XML model in the VPRED format. Finally, use it to score the test file.\n",
    "\n",
    "QuickRank provides a plugin to convert models stored in its native XML format to the textual representation employed by the original VPRED code by Nima Asadi et al. [VPRED]. The plugin outputs a textual file. \n",
    " \n",
    "The original VPred code and instructions on how to compile, install and use it are available here: https://github.com/lintool/OptTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\r\n",
      "      _____  _____\r\n",
      "     /    / /____/\r\n",
      "    /____\\ /    \\        QuickRank has been developed by hpc.isti.cnr.it\r\n",
      "    ::Quick:Rank::                             mail: quickrank@isti.cnr.it\r\n",
      "\u001b[0m\r\n",
      "generating VPred input file from: models/istella-small.lamdamart.xml\r\n"
     ]
    }
   ],
   "source": [
    "vpred_source = baseline_model_file + \".vpred\"\n",
    "\n",
    "!{QUICKRANK} \\\n",
    "  --generator vpred \\\n",
    "  --model-file {baseline_model_file} \\\n",
    "  --code-file {vpred_source}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\t0.000102983805\n",
      "Ignore this number: -2779350\n"
     ]
    }
   ],
   "source": [
    "# Now running the VPred scorer by using the previously converted code.\n",
    "# note that we are using the original VPred code by Asadi et al. [VPRED].\n",
    "# The code is available here: https://github.com/lintool/OptTrees\n",
    "\n",
    "vpred_scorer_out = !{VPRED} \\\n",
    "  -ensemble {vpred_source} \\\n",
    "  -instances {vpred_test_dataset_file} \\\n",
    "  -maxLeaves 64\n",
    "    \n",
    "print (vpred_scorer_out.n)\n",
    "\n",
    "# takes the scoring time in milli-seconds\n",
    "vpred_scoring_time = float(vpred_scorer_out.l[0].split('\\t')[1])* 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th># Trees</th>\n",
       "      <th>Scoring Time µs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CondOp</td>\n",
       "      <td>1492</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPred</td>\n",
       "      <td>1492</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model # Trees  Scoring Time µs.\n",
       "0  CondOp    1492             110.0\n",
       "1   VPred    1492             103.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "results.loc[len(results)] = ['VPred', baseline_model.n_trees, vpred_scoring_time]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "QuickScorer uses a novel traversal methods and a cache-friendly data layout that reduces dramatically the traversal time [QS-SIGIR15, QS-TOIS16]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      _____  _____\n",
      "     /    / /____\n",
      "    /____\\ _____/          QuickScorer has been developed by hpc.isti.cnr.it\n",
      "    :Quick:Scorer:                                   quickscorer@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "       Total scoring time: 15.751 s.\n",
      "Avg. Dataset scoring time: 15.751 s.\n",
      "Avg.    Doc. scoring time: 2.31208e-05 s.\n"
     ]
    }
   ],
   "source": [
    "# Now running QuickScorer.\n",
    "# note that we are using the original QuickScorer code by Lucchese et al. [QS-SIGIR15,QS-TOIS16].\n",
    "# The code is available under NDA.\n",
    "#\n",
    "# Options:\n",
    "#  -h [ --help ]                     Print help messages.\n",
    "#  -d [ --dataset ] arg              Path of the dataset to score (SVML format).\n",
    "#  -r [ --rounds ] arg (=10)         Number of test repetitions.\n",
    "#  -s [ --scores ] arg               Path of the file where final scores are\n",
    "#                                    saved.\n",
    "#  -t [ --tree_type ] arg (=0)       Specify the type of the tree in the\n",
    "#                                    ensemble:\n",
    "#                                     - 0 for normal trees,\n",
    "#                                     - 1 for oblivious trees,\n",
    "#                                     - 2 for normal trees (reversed blocked),\n",
    "#                                     - 3 for normal trees (SIMD: SSE/AVX).\n",
    "#  -m [ --model ] arg                Path of the XML file storing the model.\n",
    "#  -l [ --nleaves ] arg              Maximum number of leaves in a tree (<= 64).\n",
    "#  --avx                             Use AVX 256 instructions (at least 8 doc\n",
    "#                                    blocking).\n",
    "#  --omp                             Use OpenMP multi-threading document scoring\n",
    "#                                    (only SIMD: SSE/AVX).\n",
    "\n",
    "qs_scorer_out = !{QUICKSCORER} \\\n",
    "  -d {test_dataset_file} \\\n",
    "  -m {baseline_model_file} \\\n",
    "  -l 64 \\\n",
    "  -r 1 \\\n",
    "  -t 0\n",
    "    \n",
    "print (qs_scorer_out.n)\n",
    "    \n",
    "# takes the scoring time in milli-seconds\n",
    "qs_scoring_time = float(qs_scorer_out.l[-1].split()[-2])* 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th># Trees</th>\n",
       "      <th>Scoring Time µs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CondOp</td>\n",
       "      <td>1492</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPred</td>\n",
       "      <td>1492</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model # Trees  Scoring Time µs.\n",
       "0  CondOp    1492             110.0\n",
       "1   VPred    1492             103.0\n",
       "2      QS    1492              23.1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "results.loc[len(results)] = ['QS', baseline_model.n_trees, qs_scoring_time]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Vectorized QuickScorer improves over QuickScorer by exploiting 256-bits wide CPU registers [QS-SIGIR16].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      _____  _____\n",
      "     /    / /____\n",
      "    /____\\ _____/          QuickScorer has been developed by hpc.isti.cnr.it\n",
      "    :Quick:Scorer:                                   quickscorer@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "       Total scoring time: 10.3144 s.\n",
      "Avg. Dataset scoring time: 10.3144 s.\n",
      "Avg.    Doc. scoring time: 1.51404e-05 s.\n"
     ]
    }
   ],
   "source": [
    "# Now running Vectorized QuickScorer (AVX2)\n",
    "# note that we are using the original QuickScorer code by Lucchese et al. [QS-SIGIR16].\n",
    "# The code is available under NDA.\n",
    "#\n",
    "# Options:\n",
    "#  -h [ --help ]                     Print help messages.\n",
    "#  -d [ --dataset ] arg              Path of the dataset to score (SVML format).\n",
    "#  -r [ --rounds ] arg (=10)         Number of test repetitions.\n",
    "#  -s [ --scores ] arg               Path of the file where final scores are\n",
    "#                                    saved.\n",
    "#  -t [ --tree_type ] arg (=0)       Specify the type of the tree in the\n",
    "#                                    ensemble:\n",
    "#                                     - 0 for normal trees,\n",
    "#                                     - 1 for oblivious trees,\n",
    "#                                     - 2 for normal trees (reversed blocked),\n",
    "#                                     - 3 for normal trees (SIMD: SSE/AVX).\n",
    "#  -m [ --model ] arg                Path of the XML file storing the model.\n",
    "#  -l [ --nleaves ] arg              Maximum number of leaves in a tree (<= 64).\n",
    "#  -v [ --doc_block_size ] arg (=1)  Document block size (allowed values:\n",
    "#                                    1,2,4,8,16; 1 means no blocking).\n",
    "#  --avx                             Use AVX 256 instructions (at least 8 doc\n",
    "#                                    blocking).\n",
    "#  --omp                             Use OpenMP multi-threading document scoring\n",
    "#                                    (only SIMD: SSE/AVX).\n",
    "\n",
    "vqs_scorer_out = !{QUICKSCORER} \\\n",
    "  -d {test_dataset_file} \\\n",
    "  -m {baseline_model_file} \\\n",
    "  -l 64 \\\n",
    "  -r 1 \\\n",
    "  -t 3 \\\n",
    "  -v 8 \\\n",
    "  --avx\n",
    "    \n",
    "print (vqs_scorer_out.n)\n",
    "    \n",
    "# takes the scoring time in milli-seconds\n",
    "vqs_scoring_time = float(vqs_scorer_out.l[-1].split()[-2])* 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th># Trees</th>\n",
       "      <th>Scoring Time µs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CondOp</td>\n",
       "      <td>1492</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPred</td>\n",
       "      <td>1492</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v-QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model # Trees  Scoring Time µs.\n",
       "0  CondOp    1492             110.0\n",
       "1   VPred    1492             103.0\n",
       "2      QS    1492              23.1\n",
       "3    v-QS    1492              15.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "results.loc[len(results)] = ['v-QS', baseline_model.n_trees, vqs_scoring_time]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from [QS-TOIS16]\n",
    "\n",
    "Some considerations:\n",
    "\n",
    "0. We reproduce the evaluation methodology presented in [QS-SIGIR15, QS-TOIS16] on a different LambdaMART. The LambdaMART here is composed of 1,492 trees while results in the two papers above are for 1,000 or 5,000 trees.\n",
    "0. The scoring time is 1.5x higher than the results reported in [QS-TOIS16] for all methods. This because we are running these experiments on a slower machine than the one used for producing the experimental results presented in [QS-SIGIR15, QS-TOIS16].\n",
    "\n",
    "![caption](images/HO1-scoring.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 6\n",
    "\n",
    "Low-level statistics of the scorer with ```perf```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**perf** (https://perf.wiki.kernel.org/index.php/Tutorial) is a profiler tool for Linux 2.6+ based systems that abstracts away CPU hardware differences in Linux performance measurements and presents a simple commandline interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.1\n",
    "\n",
    "```perf``` on QuickScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      _____  _____\n",
      "     /    / /____\n",
      "    /____\\ _____/          QuickScorer has been developed by hpc.isti.cnr.it\n",
      "    :Quick:Scorer:                                   quickscorer@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "       Total scoring time: 15.8972 s.\n",
      "Avg. Dataset scoring time: 15.8972 s.\n",
      "Avg.    Doc. scoring time: 2.33353e-05 s.\n",
      "\n",
      " Performance counter stats for './QuickScorer/bin/quickscorer -d /data/letor-datasets/tiscali/sample/ramfs/test.txt -m models/istella-small.lamdamart.xml -l 64 -r 1 -t 0':\n",
      "\n",
      "   107,610,037,898 L1-dcache-loads                                              [36.37%]\n",
      "     5,800,942,942 L1-dcache-load-misses     #    5.39% of all L1-dcache hits   [36.37%]\n",
      "    55,355,326,714 L1-dcache-stores                                             [36.37%]\n",
      "       651,532,279 L1-dcache-store-misses                                       [36.37%]\n",
      "   <not supported> L1-icache-loads         \n",
      "        42,052,272 L1-icache-load-misses     #    0.00% of all L1-icache hits   [36.36%]\n",
      "   338,683,107,720 instructions              #    2.08  insns per cycle         [45.45%]\n",
      "   162,627,210,951 cycles                    [45.45%]\n",
      "     2,273,421,993 cache-references                                             [45.45%]\n",
      "        35,981,521 cache-misses              #    1.583 % of all cache refs     [45.45%]\n",
      "    70,630,367,523 branches                                                     [45.46%]\n",
      "       434,055,599 branch-misses             #    0.61% of all branches         [36.37%]\n",
      "\n",
      "      51.416314237 seconds time elapsed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below, perf is used to monitor several behaviours of the scorer:\n",
    "# - L1 cache performance (references and misses): L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses\n",
    "# - L3 cache performance (references and misses): cache-references,cache-misses\n",
    "# - number of instructions and cycles: instructions,cycles\n",
    "# - total number of branches and branch misprediction: branches,branch-misses\n",
    "\n",
    "perf_out = !{PERF} stat -e \\\n",
    "  L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,\\\n",
    "L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses,\\\n",
    "instructions,cycles,cache-references,cache-misses,branches,branch-misses\\\n",
    "    {QUICKSCORER} \\\n",
    "      -d {test_dataset_file} \\\n",
    "      -m {baseline_model_file} \\\n",
    "      -l 64 \\\n",
    "      -r 1 \\\n",
    "      -t 0\n",
    "\n",
    "print (perf_out.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing perf output\n",
    "num_istructions = int(perf_out[20].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_ref = int(perf_out[22].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_miss = int(perf_out[23].strip().split(' ')[0].replace(',', ''))\n",
    "num_branches = int(perf_out[24].strip().split(' ')[0].replace(',', ''))\n",
    "num_branch_misses = int(perf_out[25].strip().split(' ')[0].replace(',', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2\n",
    "\n",
    "```perf``` on QuickScorer (no scoring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      _____  _____\n",
      "     /    / /____\n",
      "    /____\\ _____/          QuickScorer has been developed by hpc.isti.cnr.it\n",
      "    :Quick:Scorer:                                   quickscorer@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "       Total scoring time: 6.4e-08 s.\n",
      "Avg. Dataset scoring time: 6.4e-08 s.\n",
      "Avg.    Doc. scoring time: 9.3945e-14 s.\n",
      "\n",
      " Performance counter stats for './QuickScorer-noscoring/bin/quickscorer -d /data/letor-datasets/tiscali/sample/ramfs/test.txt -m models/istella-small.lamdamart.xml -l 64 -r 1 -t 0':\n",
      "\n",
      "    54,729,913,494 L1-dcache-loads                                              [36.37%]\n",
      "       185,505,538 L1-dcache-load-misses     #    0.34% of all L1-dcache hits   [36.37%]\n",
      "    39,031,706,408 L1-dcache-stores                                             [36.37%]\n",
      "       106,537,106 L1-dcache-store-misses                                       [36.36%]\n",
      "   <not supported> L1-icache-loads         \n",
      "        36,491,652 L1-icache-load-misses     #    0.00% of all L1-icache hits   [36.37%]\n",
      "   259,957,161,960 instructions              #    2.40  insns per cycle         [45.45%]\n",
      "   108,172,068,768 cycles                    [45.45%]\n",
      "        84,884,404 cache-references                                             [45.45%]\n",
      "        34,954,115 cache-misses              #   41.178 % of all cache refs     [45.46%]\n",
      "    61,723,147,051 branches                                                     [45.45%]\n",
      "       315,402,142 branch-misses             #    0.51% of all branches         [36.37%]\n",
      "\n",
      "      34.423302964 seconds time elapsed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below, perf is used to monitor several behaviours of the scorer:\n",
    "# - L1 cache performance (references and misses): L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses\n",
    "# - L3 cache performance (references and misses): cache-references,cache-misses\n",
    "# - number of instructions and cycles: instructions,cycles\n",
    "# - total number of branches and branch misprediction: branches,branch-misses\n",
    "\n",
    "perf_noscoring_out = !{PERF} stat -e \\\n",
    "  L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,\\\n",
    "L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses,\\\n",
    "instructions,cycles,cache-references,cache-misses,branches,branch-misses\\\n",
    "    {QUICKSCORER_NS} \\\n",
    "      -d {test_dataset_file} \\\n",
    "      -m {baseline_model_file} \\\n",
    "      -l 64 \\\n",
    "      -r 1 \\\n",
    "      -t 0\n",
    "        \n",
    "print (perf_noscoring_out.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing perf output\n",
    "num_istructions_ns = int(perf_noscoring_out[20].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_ref_ns = int(perf_noscoring_out[22].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_miss_ns = int(perf_noscoring_out[23].strip().split(' ')[0].replace(',', ''))\n",
    "num_branches_ns = int(perf_noscoring_out[24].strip().split(' ')[0].replace(',', ''))\n",
    "num_branch_misses_ns = int(perf_noscoring_out[25].strip().split(' ')[0].replace(',', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.3\n",
    "\n",
    "now computing differences between the two runs to get the low level statistics for the scoring part of QS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Cache Misses</th>\n",
       "      <th>Branch Misprediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QS</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1.0e-03</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Method  Instructions  Cache Misses  Branch Misprediction\n",
       "0     QS          77.5       1.0e-03                   0.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "perf_results = pd.DataFrame(columns=['Method', 'Instructions', 'Cache Misses', 'Branch Misprediction'])\n",
    "\n",
    "normalized_instruction_count = (num_istructions - num_istructions_ns) / float(dataset_size * baseline_model.n_trees)\n",
    "normalized_cache_miss = (num_cache_miss - num_cache_miss_ns) / float(dataset_size * baseline_model.n_trees)\n",
    "normalized_branch_miss = (num_branch_misses - num_branch_misses_ns) / float(dataset_size * baseline_model.n_trees)\n",
    "\n",
    "perf_results.loc[len(perf_results)] = ['QS',\n",
    "                                  normalized_instruction_count,\n",
    "                                  normalized_cache_miss,\n",
    "                                  normalized_branch_miss]\n",
    "perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.4\n",
    "\n",
    "The same methodology now on VPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\t0.000105318109\n",
      "Ignore this number: -2779350\n",
      "\n",
      " Performance counter stats for './asadi_tkde13/out/VPred -ensemble models/istella-small.lamdamart.xml.vpred -instances /data/letor-datasets/tiscali/sample/ramfs/test.vpred -maxLeaves 64':\n",
      "\n",
      "   265,521,807,106 L1-dcache-loads                                              [36.37%]\n",
      "     1,461,322,337 L1-dcache-load-misses     #    0.55% of all L1-dcache hits   [36.37%]\n",
      "    90,022,515,465 L1-dcache-stores                                             [36.37%]\n",
      "        46,465,323 L1-dcache-store-misses                                       [36.37%]\n",
      "   <not supported> L1-icache-loads         \n",
      "     9,661,742,673 L1-icache-load-misses     #    0.00% of all L1-icache hits   [36.36%]\n",
      "   625,502,247,782 instructions              #    2.08  insns per cycle         [45.45%]\n",
      "   300,488,893,895 cycles                    [45.45%]\n",
      "    16,004,807,642 cache-references                                             [45.45%]\n",
      "        11,733,166 cache-misses              #    0.073 % of all cache refs     [45.45%]\n",
      "    41,196,965,422 branches                                                     [45.46%]\n",
      "       197,910,253 branch-misses             #    0.48% of all branches         [36.36%]\n",
      "\n",
      "      95.171206948 seconds time elapsed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below, perf is used to monitor several behaviours of the scorer:\n",
    "# - L1 cache performance (references and misses): L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses\n",
    "# - L3 cache performance (references and misses): cache-references,cache-misses\n",
    "# - number of instructions and cycles: instructions,cycles\n",
    "# - total number of branches and branch misprediction: branches,branch-misses\n",
    "\n",
    "vpred_perf_out = !{PERF} stat -e \\\n",
    "  L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,\\\n",
    "L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses,\\\n",
    "instructions,cycles,cache-references,cache-misses,branches,branch-misses\\\n",
    "    {VPRED} \\\n",
    "      -ensemble {vpred_source} \\\n",
    "      -instances {vpred_test_dataset_file} \\\n",
    "      -maxLeaves 64\n",
    "        \n",
    "print (vpred_perf_out.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing perf output\n",
    "num_istructions = int(vpred_perf_out[11].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_ref = int(vpred_perf_out[13].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_miss = int(vpred_perf_out[14].strip().split(' ')[0].replace(',', ''))\n",
    "num_branches = int(vpred_perf_out[15].strip().split(' ')[0].replace(',', ''))\n",
    "num_branch_misses = int(vpred_perf_out[16].strip().split(' ')[0].replace(',', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.5\n",
    "\n",
    "``perf`` on VPred (no scoring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\t1.48256881e-13\n",
      "Ignore this number: 0\n",
      "\n",
      " Performance counter stats for './asadi_tkde13-noscoring/out/VPred -ensemble models/istella-small.lamdamart.xml.vpred -instances /data/letor-datasets/tiscali/sample/ramfs/test.vpred -maxLeaves 64':\n",
      "\n",
      "    43,941,623,126 L1-dcache-loads                                              [36.37%]\n",
      "        49,346,422 L1-dcache-load-misses     #    0.11% of all L1-dcache hits   [36.37%]\n",
      "    31,270,056,480 L1-dcache-stores                                             [36.37%]\n",
      "        24,291,207 L1-dcache-store-misses                                       [36.36%]\n",
      "   <not supported> L1-icache-loads         \n",
      "         8,301,655 L1-icache-load-misses     #    0.00% of all L1-icache hits   [36.35%]\n",
      "   175,562,118,101 instructions              #    2.37  insns per cycle         [45.46%]\n",
      "    74,077,992,866 cycles                    [45.46%]\n",
      "        23,344,652 cache-references                                             [45.46%]\n",
      "         7,768,084 cache-misses              #   33.276 % of all cache refs     [45.46%]\n",
      "    40,908,736,435 branches                                                     [45.46%]\n",
      "       154,669,511 branch-misses             #    0.38% of all branches         [36.37%]\n",
      "\n",
      "      23.491616902 seconds time elapsed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below, perf is used to monitor several behaviours of the scorer:\n",
    "# - L1 cache performance (references and misses): L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses\n",
    "# - L3 cache performance (references and misses): cache-references,cache-misses\n",
    "# - number of instructions and cycles: instructions,cycles\n",
    "# - total number of branches and branch misprediction: branches,branch-misses\n",
    "\n",
    "vpred_perf_noscoring_out = !{PERF} stat -e \\\n",
    "  L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores,\\\n",
    "L1-dcache-store-misses,L1-icache-loads,L1-icache-load-misses,\\\n",
    "instructions,cycles,cache-references,cache-misses,branches,branch-misses\\\n",
    "    {VPRED_NS} \\\n",
    "      -ensemble {vpred_source} \\\n",
    "      -instances {vpred_test_dataset_file} \\\n",
    "      -maxLeaves 64\n",
    "        \n",
    "print (vpred_perf_noscoring_out.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing perf output\n",
    "num_istructions_ns = int(vpred_perf_noscoring_out[11].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_ref_ns = int(vpred_perf_noscoring_out[13].strip().split(' ')[0].replace(',', ''))\n",
    "num_cache_miss_ns = int(vpred_perf_noscoring_out[14].strip().split(' ')[0].replace(',', ''))\n",
    "num_branches_ns = int(vpred_perf_noscoring_out[15].strip().split(' ')[0].replace(',', ''))\n",
    "num_branch_misses_ns = int(vpred_perf_noscoring_out[16].strip().split(' ')[0].replace(',', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.6\n",
    "\n",
    "now computing differences between the two runs to get the low level statistics for the scoring part of VPred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Cache Misses</th>\n",
       "      <th>Branch Misprediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QS</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1.0e-03</td>\n",
       "      <td>1.2e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPred</td>\n",
       "      <td>442.7</td>\n",
       "      <td>3.9e-03</td>\n",
       "      <td>4.3e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Method  Instructions  Cache Misses  Branch Misprediction\n",
       "0     QS          77.5       1.0e-03               1.2e-01\n",
       "1  VPred         442.7       3.9e-03               4.3e-02"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "normalized_instruction_count = (num_istructions - num_istructions_ns) / float(dataset_size * baseline_model.n_trees)\n",
    "normalized_cache_miss = (num_cache_miss - num_cache_miss_ns) / float(dataset_size * baseline_model.n_trees)\n",
    "normalized_branch_miss = (num_branch_misses - num_branch_misses_ns) / float(dataset_size * baseline_model.n_trees)\n",
    "\n",
    "perf_results.loc[len(perf_results)] = ['VPred',\n",
    "                                  normalized_instruction_count,\n",
    "                                  normalized_cache_miss,\n",
    "                                  normalized_branch_miss]\n",
    "perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.7\n",
    "\n",
    "from [QS-TOIS16]\n",
    "\n",
    "Some considerations:\n",
    "\n",
    "0. We reproduce the methodology presented in [QS-SIGIR15, QS-TOIS16] on a different LambdaMART. The LambdaMART here is composed of 1,492 trees while results in the two papers above are for 1,000 or 5,000 trees. Given that said, the low level behavior of the two methods is confirmed.\n",
    "0. The number of instructions executed by VPred is the largest one. This is because VPred always runs ``d`` steps, where ``d`` is the depth of a tree even if a document might reach an exit leaf earlier. On the other hand, QS executes the smallest number instructions. This is due to the different traversal strategy of the ensemble, as QS needs to process the false nodes only.\n",
    "0. In terms of number of branches, we note that QS has a larger total number of branch mispredictions than VPred, which uses scoring functions that are branch-free.\n",
    "0. In terms of cache misses, we note that QS has a lower cache miss. This is mostly due to the new data layout of QS that perform document scoring by means of linear scans of arrays.\n",
    "\n",
    "![caption](images/HO1-lowlevelperf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "We developed a Multithreaded implementation of Vectorized QuickScorer that exploits OpenMP to distribute bunches of documents to threads scoring them in parallel. [QS-TPDS18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up environment variables for OpenMP\n",
    "os.environ['OMP_NUM_THREADS']='32'\n",
    "os.environ['OMP_DISPLAY_ENV']='VERBOSE'\n",
    "os.environ['OMP_SCHEDULE']='auto'\n",
    "os.environ['GOMP_CPU_AFFINITY']='0-7,8-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OPENMP DISPLAY ENVIRONMENT BEGIN\n",
      "  _OPENMP = '201511'\n",
      "  OMP_DYNAMIC = 'FALSE'\n",
      "  OMP_NESTED = 'FALSE'\n",
      "  OMP_NUM_THREADS = '32'\n",
      "  OMP_SCHEDULE = 'AUTO'\n",
      "  OMP_PROC_BIND = 'TRUE'\n",
      "  OMP_PLACES = '{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15}'\n",
      "  OMP_STACKSIZE = '0'\n",
      "  OMP_WAIT_POLICY = 'PASSIVE'\n",
      "  OMP_THREAD_LIMIT = '4294967295'\n",
      "  OMP_MAX_ACTIVE_LEVELS = '2147483647'\n",
      "  OMP_CANCELLATION = 'FALSE'\n",
      "  OMP_DEFAULT_DEVICE = '0'\n",
      "  OMP_MAX_TASK_PRIORITY = '0'\n",
      "  GOMP_CPU_AFFINITY = ''\n",
      "  GOMP_STACKSIZE = '0'\n",
      "  GOMP_SPINCOUNT = '300000'\n",
      "OPENMP DISPLAY ENVIRONMENT END\n",
      "\n",
      "      _____  _____\n",
      "     /    / /____\n",
      "    /____\\ _____/          QuickScorer has been developed by hpc.isti.cnr.it\n",
      "    :Quick:Scorer:                                   quickscorer@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "       Total scoring time: 0.848875 s.\n",
      "Avg. Dataset scoring time: 0.848875 s.\n",
      "Avg.    Doc. scoring time: 1.24606e-06 s.\n"
     ]
    }
   ],
   "source": [
    "# Now running Multi-threaded Vectorized QuickScorer.\n",
    "# Options:\n",
    "#  -h [ --help ]                     Print help messages.\n",
    "#  -d [ --dataset ] arg              Path of the dataset to score (SVML format).\n",
    "#  -r [ --rounds ] arg (=10)         Number of test repetitions.\n",
    "#  -s [ --scores ] arg               Path of the file where final scores are\n",
    "#                                    saved.\n",
    "#  -t [ --tree_type ] arg (=0)       Specify the type of the tree in the\n",
    "#                                    ensemble:\n",
    "#                                     - 0 for normal trees,\n",
    "#                                     - 1 for oblivious trees,\n",
    "#                                     - 2 for normal trees (reversed blocked),\n",
    "#                                     - 3 for normal trees (SIMD: SSE/AVX).\n",
    "#  -m [ --model ] arg                Path of the XML file storing the model.\n",
    "#  -l [ --nleaves ] arg              Maximum number of leaves in a tree (<= 64).\n",
    "#  -v [ --doc_block_size ] arg (=1)  Document block size (allowed values:\n",
    "#                                    1,2,4,8,16; 1 means no blocking).\n",
    "#  --avx                             Use AVX 256 instructions (at least 8 doc\n",
    "#                                    blocking).\n",
    "#  --omp                             Use OpenMP multi-threading document scoring\n",
    "#                                    (only SIMD: SSE/AVX).\n",
    "\n",
    "scorer_out = !{QUICKSCORER} \\\n",
    "  -d {test_dataset_file} \\\n",
    "  -m {baseline_model_file} \\\n",
    "  -l 64 \\\n",
    "  -r 1 \\\n",
    "  -t 3 \\\n",
    "  -v 8 \\\n",
    "  --avx \\\n",
    "  --omp\n",
    "    \n",
    "print (scorer_out.n)\n",
    "    \n",
    "# takes the scoring time in milli-seconds\n",
    "scoring_time = float(scorer_out.l[-1].split()[-2])* 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th># Trees</th>\n",
       "      <th>Scoring Time µs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CondOp</td>\n",
       "      <td>1492</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPred</td>\n",
       "      <td>1492</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v-QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vQS-OMP</td>\n",
       "      <td>1492</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model # Trees  Scoring Time µs.\n",
       "0   CondOp    1492             110.0\n",
       "1    VPred    1492             103.0\n",
       "2       QS    1492              23.1\n",
       "3     v-QS    1492              15.1\n",
       "4  vQS-OMP    1492               1.2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "results.loc[len(results)] = ['vQS-OMP', baseline_model.n_trees, scoring_time]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "\n",
    "We developed a GPU implementation of QuickScorer. This test below works on a NVIDIA Titan Xp card. [QS-TPDS18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      _____  _____\n",
      "     /    / /____\n",
      "    /____\\ _____/          QuickScorer has been developed by Tiscali SpA, CNR, Univ. of Pisa, Univ. of Venezia\n",
      "    :Quick:Scorer:                                                                      quickscorer@isti.cnr.it\n",
      "\n",
      "#\t Dataset size: 681250 x 220 (instances x features)\n",
      "#\t Num queries: 6562 | Avg. len: 104\n",
      "Using a GPU-based strategy!\n",
      "GPU INFO: Mem free at START: 12600672256 (total: 12782075904)\n",
      "Building the model...\n",
      "Scoring...\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.317502 s.\n",
      "GPU => Avg. scoring time: 0.317502 s.\n",
      "GPU => Avg. scoring time per doc.: 4.66058e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.286065 s.\n",
      "GPU => Avg. scoring time: 0.301784 s.\n",
      "GPU => Avg. scoring time per doc.: 4.42985e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.28048 s.\n",
      "GPU => Avg. scoring time: 0.294682 s.\n",
      "GPU => Avg. scoring time per doc.: 4.32561e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.281848 s.\n",
      "GPU => Avg. scoring time: 0.291474 s.\n",
      "GPU => Avg. scoring time per doc.: 4.27851e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.282098 s.\n",
      "GPU => Avg. scoring time: 0.289599 s.\n",
      "GPU => Avg. scoring time per doc.: 4.25099e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.280757 s.\n",
      "GPU => Avg. scoring time: 0.288125 s.\n",
      "GPU => Avg. scoring time per doc.: 4.22936e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.279372 s.\n",
      "GPU => Avg. scoring time: 0.286875 s.\n",
      "GPU => Avg. scoring time per doc.: 4.211e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.282373 s.\n",
      "GPU => Avg. scoring time: 0.286312 s.\n",
      "GPU => Avg. scoring time per doc.: 4.20274e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.282316 s.\n",
      "GPU => Avg. scoring time: 0.285868 s.\n",
      "GPU => Avg. scoring time per doc.: 4.19623e-07 s.\n",
      "GPU => # of trees 1492 (max per block: 4000)\n",
      "GPU => size treeIDs + masks + thresholds: 1503936 bytes\n",
      "GPU => size vec temporary offsets: 884 bytes\n",
      "GPU => size tree score table: 763904 bytes\n",
      "GPU => size doc result scores: 5450000 bytes\n",
      "GPU => Size of a block of instances processed at once: 305040\n",
      "GPU => Global memory reserved for the block of instances: 1073740800 bytes\n",
      "GPU => Executing 16384 blocks, 384 threads per block\n",
      "GPU => 32000 bytes shared mem allocated x CUDA-block\n",
      "GPU => Processing docs [0-305040) (305040 docs)\n",
      "GPU => Processing docs [305040-610080) (305040 docs)\n",
      "GPU => Processing docs [610080-681250) (71170 docs)\n",
      "GPU => scoring time: 0.281964 s.\n",
      "GPU => Avg. scoring time: 0.285478 s.\n",
      "GPU => Avg. scoring time per doc.: 4.1905e-07 s.\n",
      "       Total scoring time: 2.85478 s.\n",
      "Avg. Dataset scoring time: 0.285478 s.\n",
      "Avg.    Doc. scoring time: 4.1905e-07 s.\n",
      "0.41905\n"
     ]
    }
   ],
   "source": [
    "# Now running GPU QuickScorer.\n",
    "# Options:\n",
    "#   -h [ --help ]                     Print help messages\n",
    "#   -d [ --dataset ] arg              Input dataset in SVML format\n",
    "#   -r [ --rounds ] arg (=10)         Number of test repetitions\n",
    "#   -s [ --scores ] arg               File where scores are saved\n",
    "#   -w [ --warmup ] arg               Warmp dataset in SVML format used for\n",
    "#                                     reversed trees\n",
    "#   -m [ --model ] arg                File storing the model\n",
    "#   -l [ --nleaves ] arg              Maximum number of leaves in a tree (<= 64)\n",
    "#   -b [ --tree_block_size ] arg (=1) Tree block size (1 means no blocking)\n",
    "#   -v [ --doc_block_size ] arg (=1)  Documents block size (allowed: 1,2,4,8,16;\n",
    "#                                     1 means no blocking)\n",
    "#   -y [ --cuda_threads ] arg (=256)  Number of threads per CUDA block (allowed:\n",
    "#                                     96,128,192,256,384,512,768,1024; default:\n",
    "#                                     256)\n",
    "#   -z [ --cuda_blocks ] arg (=32768) Number CUDA blocks used by the scoring\n",
    "#                                     kernel (default: 1024 * 32)\n",
    "\n",
    "scorer_out = !{QUICKSCORER_GPU} \\\n",
    "    -m {baseline_model_file} \\\n",
    "    -t 1 -l 64 -r 10 -b 4000 -y 384 -z 16384 \\\n",
    "    -d {test_dataset_file}\n",
    "\n",
    "print (scorer_out.n)\n",
    "\n",
    "# takes the scoring time in milli-seconds\n",
    "scoring_time = float(scorer_out.l[-2].split()[-2])* 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th># Trees</th>\n",
       "      <th>Scoring Time µs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CondOp</td>\n",
       "      <td>1492</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPred</td>\n",
       "      <td>1492</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v-QS</td>\n",
       "      <td>1492</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vQS-OMP</td>\n",
       "      <td>1492</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QS-GPU</td>\n",
       "      <td>1492</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model # Trees  Scoring Time µs.\n",
       "0   CondOp    1492             110.0\n",
       "1    VPred    1492             103.0\n",
       "2       QS    1492              23.1\n",
       "3     v-QS    1492              15.1\n",
       "4  vQS-OMP    1492               1.2\n",
       "5  QS-GPU    1492               0.4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store current results\n",
    "results.loc[len(results)] = ['QS-GPU', baseline_model.n_trees, scoring_time]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9\n",
    "\n",
    "RankEval (http://rankeval.isti.cnr.it) - multithread scoring written in Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files. This may take a few minutes.\n",
      "done loading dataset!\n"
     ]
    }
   ],
   "source": [
    "from rankeval.dataset.datasets_fetcher import load_dataset\n",
    "\n",
    "dataset_container = load_dataset(dataset_name='istella-sample',\n",
    "                                download_if_missing=True, \n",
    "                                force_download=False, \n",
    "                                with_models=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 39719.63 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 256 µs per loop\n"
     ]
    }
   ],
   "source": [
    "# We now use RankEval to score the test file.\n",
    "scorer_out = %timeit -o baseline_model.score(dataset_container.test_dataset, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[VPRED] Asadi et al. Runtime Optimizations for Tree-Based Machine Learning Models. IEEE Trans. Knowl. Data Eng. 26(9): 2281-2292 (2014).\n",
    "\n",
    "[QS-SIGIR15] Lucchese et al. QuickScorer: A Fast Algorithm to Rank Documents with Additive Ensembles of Regression Trees. ACM SIGIR 2015. Best Paper Award.\n",
    "\n",
    "[QS-TOIS16] Dato et al. Fast Ranking with Additive Ensembles of Oblivious and Non-Oblivious Regression Trees. ACM TOIS, Vol. 9, No. 4. Dec. 2016.\n",
    "\n",
    "[QS-SIGIR16] Lucchese et al. Exploiting CPU SIMD Extensions to Speed-up Document Scoring with Tree Ensembles. ACM SIGIR 2016.\n",
    "\n",
    "[QS-TPDS18]  Lettich et al. Parallel Traversal of Large Ensembles of Decision Trees. IEEE TPDS. 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
